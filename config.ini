;paths for data
[paths]
base_fp     = /Users/dewalgupta/Documents/ucsd/nlp/qanet
TRAIN       = ${base_fp}/data/squad/train-v1.1.json
VAL         = ${base_fp}/data/squad/dev-v1.1.json
GLOVE       = ${base_fp}/data/glove.840B.300d.txt
TRAIN_REC   = ${base_fp}/data/train.tfrecords
DEV_REC     = ${base_fp}/data/dev.tfrecords
TEST_REC    = ${base_fp}/data/test.tfrecords
TMPDIR      = ${base_fp}/tmp
LOGDIR      = ${base_fp}/log

; preprocessed files
word_emb    = ${base_fp}/data/word_emb.json
char_emb    = ${base_fp}/data/char_emb.json
train_eval  = ${base_fp}/data/train_eval.json
dev_eval    = ${base_fp}/data/dev_eval.json
dev_meta    = ${base_fp}/data/dev_meta.json
test_eval    = ${base_fp}/data/test_eval.json
test_meta    = ${base_fp}/data/test_meta.json

word_dict    = ${base_fp}/data/word_dict.json
char_dict    = ${base_fp}/data/char_dict.json

; hyperparameters
[hp]
NUM_GPUS          = 2
BATCH_SIZE        = 3
DROPOUT_KEEP_PROB = 0.2
MAX_EPOCH         = 100
LR                = 0.01 
; can change it to exponentially decay with global steps

;iteration related params
[iter]
DISPLAY_ITER      = 100
SAVE_ITER         = 1000
VAL_ITER          = 1000
THROUGH_PUT_ITER  = 99
SAVER_MAX_TO_KEEP = 10
SHUFFLE_BUFFER    = 10

;limits, dimensions
[dim]
char_dim          = 64
para_limit        = 400
ques_limit        = 50
ans_limit         = 30
test_para_limit   = 1000
test_ques_limit   = 100
char_limit        = 16
word_count_limit  = -1
char_count_limit  = -1
glove_size        = 2200000
glove_dim         = 300
batch_capacity    = 5
batch_size        = 1
num_threads       = 4
hidden_layer_size = 96
